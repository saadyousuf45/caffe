{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/saadi/Desktop/test_xml _write/textfile_faceloactions/7.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/6.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/4.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/0.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/2.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/8.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/3.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/1.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/9.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/10.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/5.txt']\n",
      "###################################################\n",
      "['/home/saadi/Desktop/test_xml _write/textfile_faceloactions/0.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/1.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/2.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/3.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/4.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/5.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/6.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/7.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/8.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/9.txt', '/home/saadi/Desktop/test_xml _write/textfile_faceloactions/10.txt']\n",
      "['/home/saadi/Desktop/test_xml _write/annotations/4.xml', '/home/saadi/Desktop/test_xml _write/annotations/9.xml', '/home/saadi/Desktop/test_xml _write/annotations/6.xml', '/home/saadi/Desktop/test_xml _write/annotations/1.xml', '/home/saadi/Desktop/test_xml _write/annotations/2.xml', '/home/saadi/Desktop/test_xml _write/annotations/0.xml', '/home/saadi/Desktop/test_xml _write/annotations/8.xml', '/home/saadi/Desktop/test_xml _write/annotations/5.xml', '/home/saadi/Desktop/test_xml _write/annotations/10.xml', '/home/saadi/Desktop/test_xml _write/annotations/7.xml', '/home/saadi/Desktop/test_xml _write/annotations/3.xml']\n",
      "###################################################\n",
      "['/home/saadi/Desktop/test_xml _write/annotations/0.xml', '/home/saadi/Desktop/test_xml _write/annotations/1.xml', '/home/saadi/Desktop/test_xml _write/annotations/2.xml', '/home/saadi/Desktop/test_xml _write/annotations/3.xml', '/home/saadi/Desktop/test_xml _write/annotations/4.xml', '/home/saadi/Desktop/test_xml _write/annotations/5.xml', '/home/saadi/Desktop/test_xml _write/annotations/6.xml', '/home/saadi/Desktop/test_xml _write/annotations/7.xml', '/home/saadi/Desktop/test_xml _write/annotations/8.xml', '/home/saadi/Desktop/test_xml _write/annotations/9.xml', '/home/saadi/Desktop/test_xml _write/annotations/10.xml']\n",
      "['/home/saadi/Desktop/test_xml _write/images/8.jpg', '/home/saadi/Desktop/test_xml _write/images/10.jpg', '/home/saadi/Desktop/test_xml _write/images/4.jpg', '/home/saadi/Desktop/test_xml _write/images/7.jpg', '/home/saadi/Desktop/test_xml _write/images/6.jpg', '/home/saadi/Desktop/test_xml _write/images/2.jpg', '/home/saadi/Desktop/test_xml _write/images/0.jpg', '/home/saadi/Desktop/test_xml _write/images/3.jpg', '/home/saadi/Desktop/test_xml _write/images/5.jpg', '/home/saadi/Desktop/test_xml _write/images/1.jpg', '/home/saadi/Desktop/test_xml _write/images/9.jpg']\n",
      "###################################################\n",
      "['/home/saadi/Desktop/test_xml _write/images/0.jpg', '/home/saadi/Desktop/test_xml _write/images/1.jpg', '/home/saadi/Desktop/test_xml _write/images/2.jpg', '/home/saadi/Desktop/test_xml _write/images/3.jpg', '/home/saadi/Desktop/test_xml _write/images/4.jpg', '/home/saadi/Desktop/test_xml _write/images/5.jpg', '/home/saadi/Desktop/test_xml _write/images/6.jpg', '/home/saadi/Desktop/test_xml _write/images/7.jpg', '/home/saadi/Desktop/test_xml _write/images/8.jpg', '/home/saadi/Desktop/test_xml _write/images/9.jpg', '/home/saadi/Desktop/test_xml _write/images/10.jpg']\n"
     ]
    }
   ],
   "source": [
    "### creates a list of paths of text files to read face locations \n",
    "import os\n",
    "txt_list= [os.path.join('/home/saadi/Desktop/test_xml _write/textfile_faceloactions', file) for file in os.listdir('/home/saadi/Desktop/test_xml _write/textfile_faceloactions') if file.endswith('.txt')]\n",
    "print(txt_list)\n",
    "txt_list.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))# reorganizes the list\n",
    "print('###################################################')\n",
    "print(txt_list)\n",
    "\n",
    "### creates a list of paths of xml files to write age and gender labels\n",
    "import os\n",
    "xml_list= [os.path.join('/home/saadi/Desktop/test_xml _write/annotations', file) for file in os.listdir('/home/saadi/Desktop/test_xml _write/annotations') if file.endswith('.xml')]\n",
    "print(xml_list)\n",
    "xml_list.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))# reorganizes the list\n",
    "print('###################################################')\n",
    "print(xml_list)\n",
    "\n",
    "#creates a list of file paths of images in a folder for python 3\n",
    "import os\n",
    "img_list= [os.path.join('/home/saadi/Desktop/test_xml _write/images', file) for file in os.listdir('/home/saadi/Desktop/test_xml _write/images') if file.endswith('.jpg')]\n",
    "print(img_list)\n",
    "img_list.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))# reorganizes the list\n",
    "print('###################################################')\n",
    "print(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "#sys.path.append('/usr/lib/python2.7/dist-packages')\n",
    "import caffe\n",
    "import matplotlib.pyplot as plt\n",
    "net = caffe.Net('/home/saadi/caffe_ssd/models/AgeGender/IMDB/Age-finetuned/age.prototxt',\n",
    "                '/home/saadi/caffe_ssd/models/AgeGender/IMDB/Age-finetuned/dex_chalearn_iccv2015.caffemodel',\n",
    "                caffe.TEST)\n",
    "print 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run /home/saad/caffe/python/draw_net.py /home/saad/caffe/Caffe models/age.prototxt my.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.set_mean('data', np.load('/home/saadi/caffe_ssd/python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_channel_swap('data', (2,1,0)) # if using RGB instead of BGR\n",
    "transformer.set_raw_scale('data', 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.blobs['data'].reshape(1,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=2, thickness=3):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (0, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 100, 100), thickness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Image height is =', 1288)\n",
      "('Image width is =', 1998)\n",
      "('The Number of faces are=', 13)\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1f8ea4bd3507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m#time.sleep(15)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;31m#time.sleep(5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m#print('The output is', output['prob'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/caffe_ssd/python/caffe/pycaffe.pyc\u001b[0m in \u001b[0;36m_Net_forward\u001b[0;34m(self, blobs, start, end, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Unpack blobs to extract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "img_size = 224\n",
    "\n",
    "for img, txt, k in zip(img_list, txt_list, xml_list):\n",
    "    img = caffe.io.load_image(img)    # here goes the image file path\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #print(input_img)\n",
    "    #plt.imshow(img)\n",
    "    img_h, img_w, _ = np.shape(img)\n",
    "    print('Image height is =',img_h)\n",
    "    print('Image width is =',img_w)\n",
    "    \n",
    "    \n",
    "    \n",
    "    f= open(txt, 'r')\n",
    "    counter = 0    #  for reading detected faces only\n",
    "    locations=[]\n",
    "    r = 0 # this is for faces[r, :, :, :] = cv2.resize(img[yw1:yw2 + 0, xw1:xw2 + 0, :]\n",
    "    for line in f :  # line is a string\n",
    "        if counter == 0:\n",
    "            firstline_faces=list(map(int,line.split()))\n",
    "            Number_face_detected=(firstline_faces[0])\n",
    "            print('The Number of faces are=',firstline_faces[0])\n",
    "            faces_detected= firstline_faces[0]\n",
    "            counter = counter +1\n",
    "        else :\n",
    "            \n",
    "            transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "            transformer.set_mean('data', np.load('/home/saadi/caffe_ssd/python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1))\n",
    "            transformer.set_transpose('data', (2,0,1))\n",
    "            transformer.set_channel_swap('data', (2,1,0)) # if using RGB instead of BGR\n",
    "            transformer.set_raw_scale('data', 255.0)\n",
    "            net.blobs['data'].reshape(1,3,224,224)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            face_coordinates=list(map(int,line.split()))\n",
    "            #print(face_coordinates)\n",
    "\n",
    "            x1 = face_coordinates[0]\n",
    "            y1 = face_coordinates[1]\n",
    "            x2 = face_coordinates[2]\n",
    "            y2 = face_coordinates[3]\n",
    "\n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "\n",
    "            xw1 = max(int(x1 - 0.1 * w), 0)\n",
    "            yw1 = max(int(y1 - 0.1 * h), 0)\n",
    "            xw2 = min(int(x2 + 0.1 * w), img_w - 1)\n",
    "            yw2 = min(int(y2 + 0.1 * h), img_h - 1)\n",
    "\n",
    "\n",
    "            locations.append([xw1, yw1])\n",
    "\n",
    "            #print(locations[0][1]) # this makes a list to print predictions\n",
    "\n",
    "\n",
    "            faces = np.empty((1, img_size, img_size, 3))\n",
    "\n",
    "            #cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.rectangle(img, (xw1, yw1), (xw2, yw2), (255, 0, 0), 2)\n",
    "\n",
    "            image = cv2.resize(img[yw1:yw2 + 0, xw1:xw2 + 0, :], (img_size, img_size))\n",
    "            #plt.imshow(image)\n",
    "\n",
    "            net.blobs['data'].data[...] = transformer.preprocess('data', image)\n",
    "            #time.sleep(15)\n",
    "            output = net.forward()\n",
    "            #time.sleep(5)\n",
    "            #print('The output is', output['prob'])\n",
    "            print output['prob'].argmax()\n",
    "            label = \"{} \".format(output['prob'].argmax())\n",
    "            draw_label(img,(xw1, yw1), label)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(img)\n",
    "    plt.draw()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/ilsvrc12/synset_words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-164303b6d1cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/ilsvrc12/synset_words.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/caffe/local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'U'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/ilsvrc12/synset_words.txt'"
     ]
    }
   ],
   "source": [
    "label_mapping = np.loadtxt(\"data/ilsvrc12/synset_words.txt\", str, delimiter='\\t')\n",
    "best_n = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]\n",
    "print label_mapping[best_n]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
